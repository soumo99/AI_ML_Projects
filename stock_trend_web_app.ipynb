{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_trend_web_app.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNvzEgLsaiWHfE3Ku1IGxFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumo99/AI_ML_Projects/blob/main/stock_trend_web_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nV8A9Vv3z-W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader as data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = '2010-01-01'\n",
        "end = '2019-12-31'\n",
        "\n",
        "#Scraping the data from yahoo finance website\n",
        "df = data.DataReader('AAPL','yahoo', start, end)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CieC7GG154ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project is mainly based on the closing price for the particular date "
      ],
      "metadata": {
        "id": "TeZr1bSbq2tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas-datareader"
      ],
      "metadata": {
        "id": "oBCP-lbtbTp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pandas"
      ],
      "metadata": {
        "id": "08s10df7az9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pandas-datareader"
      ],
      "metadata": {
        "id": "j9k-12Wha4oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "JWxFS3vjgoNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.reset_index()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "fQAJNcmjgtPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Date','Adj Close'],axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jMTUvkcqgwQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df.Close)"
      ],
      "metadata": {
        "id": "oKoFgJXQgzi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "0259DgnJg2EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the 100 days moving average(the averages of a time frame) so the firsr 100 days(so it will take the 100 days closing price and will find the average) it will be null \n",
        "ma_100 = df.Close.rolling(100).mean()\n",
        "ma_100"
      ],
      "metadata": {
        "id": "t4SUYdY2g3u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the graph for 100 days moving average \n",
        "plt.figure(figsize = (12,6))\n",
        "plt.plot(df.Close)\n",
        "plt.plot(ma_100,'r')"
      ],
      "metadata": {
        "id": "VhMMypqPg72X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the 200 days moving average so the firsr 100 days it will be null \n",
        "ma_200 = df.Close.rolling(200).mean()\n",
        "ma_200"
      ],
      "metadata": {
        "id": "KNR4Vz7RhJma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the graph for 200 days moving average \n",
        "plt.figure(figsize = (12,6))\n",
        "plt.plot(df.Close)\n",
        "plt.plot(ma_200,'r')"
      ],
      "metadata": {
        "id": "nNbRBa6IhPFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the combined graph of 100 and 200 days moving average \n",
        "plt.figure(figsize = (12,6))\n",
        "plt.plot(df.Close)\n",
        "plt.plot(ma_100,'g')\n",
        "plt.plot(ma_200,'r')\n"
      ],
      "metadata": {
        "id": "6SpRVaibhQup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ykiwf-afhTt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main data will be the closing column "
      ],
      "metadata": {
        "id": "wPHaWBEdhZNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into 70% training data and 30% testing data\n",
        "data_training = pd.DataFrame(df['Close'][0:int(len(df)*0.70)])\n",
        "data_testing = pd.DataFrame(df['Close'][int(len(df)*0.70):int(len(df))])\n",
        "print(data_training.shape)\n",
        "print(data_testing.shape)"
      ],
      "metadata": {
        "id": "2ud8xryehWss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_training.head()"
      ],
      "metadata": {
        "id": "co_9KMmthfRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_testing.head()"
      ],
      "metadata": {
        "id": "iO4gKmkehiDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for stack LSTM model we have scale down the data \n",
        "#we will scale the data between 0 and 1\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))"
      ],
      "metadata": {
        "id": "9r7YuIiGhlE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the datas \n",
        "data_training_array = scaler.fit_transform(data_training)\n",
        "data_training_array"
      ],
      "metadata": {
        "id": "F0FG_MkZhodB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide the data into x train and y train \n",
        "#the next days price will be totally dependent on the previous days data and when again the next days data will be calculated the first days data will be deducted so like this the whole process will carry on  \n",
        "x_train = [] #previous days data (featured class)\n",
        "y_train = [] #next days data (predicted class)\n",
        "\n",
        "#here the steps are starting from 100 \n",
        "\n",
        "for i in range(100,data_training.shape[0]):\n",
        "    x_train.append(data_training_array[i-100:i])\n",
        "    y_train.append(data_training_array[i,0])\n",
        "    \n",
        "    \n",
        "x_train, y_train = np.array(x_train),np.array(y_train)"
      ],
      "metadata": {
        "id": "70ftlBYihr65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Machine Learning Model "
      ],
      "metadata": {
        "id": "L10lyzDwhu4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense,Dropout,LSTM\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "5NG_xPjZhv_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 4 layers of the LSTM Model"
      ],
      "metadata": {
        "id": "Rkd9vFrrrpUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FIRST LAYER\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50,activation='relu',return_sequences=True,\n",
        "               input_shape=(x_train.shape[1],1)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#SECOND LAYER\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=60,activation='relu',return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#THIRD LAYER\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=80,activation='relu',return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#LAST LAYER\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=120,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "YphGpnLGioEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For loss mean squared error is being used because we are doing time series analysis(for predicting the next values we need to calculate the previous values) and for that mean squared error is being used \n",
        "model.compile(optimizer='adam',loss = 'mean_squared_error')\n",
        "model.fit(x_train,y_train,epochs=50)"
      ],
      "metadata": {
        "id": "toU5bPdPqIde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('keras_model.h5')"
      ],
      "metadata": {
        "id": "Uwv_VLlPsL0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_training.tail(100)"
      ],
      "metadata": {
        "id": "l-RlDUS8s3LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past_100_days = data_training.tail(100)"
      ],
      "metadata": {
        "id": "E5NlM9SaswIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = past_100_days.append(data_testing, ignore_index=True)"
      ],
      "metadata": {
        "id": "15kUiI3ns-ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "9roSxSH3tWFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the datas by using the Min Max Scaler because the above table datas are not scaled down "
      ],
      "metadata": {
        "id": "3VuntWqjte-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#So all the rows are being scaled down between 0 and 1\n",
        "input_data = scaler.fit_transform(final_df)\n",
        "input_data"
      ],
      "metadata": {
        "id": "A8EBad_htifS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data.shape"
      ],
      "metadata": {
        "id": "kCFcy5aDuK8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for i in range(100,input_data.shape[0]):\n",
        "  x_test.append(input_data[i-100:i])\n",
        "  y_test.append(input_data[i,0])\n"
      ],
      "metadata": {
        "id": "D79izLwwuPhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = np.array(x_test),np.array(y_test)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "fti13JIWDP7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making Predictions "
      ],
      "metadata": {
        "id": "G1bSpjHZDp-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(x_test)\n"
      ],
      "metadata": {
        "id": "-ppdw-DoDrgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted.shape"
      ],
      "metadata": {
        "id": "BDVbMPmkDyIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "xDrm8eoaD5Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted"
      ],
      "metadata": {
        "id": "40CegvkmD7WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the factor by which all the valuea are scaled down \n",
        "scaler.scale_"
      ],
      "metadata": {
        "id": "sUV6H46nD_V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale_factor = 1/0.02099517\n",
        "y_predicted = y_predicted * scale_factor\n",
        "y_test = y_test * scale_factor"
      ],
      "metadata": {
        "id": "5wKNeY2OEVTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_test,'b',label = 'Original Price')\n",
        "plt.plot(y_predicted,'r',label = 'Predicted Price')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K4jji_obEmL7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}